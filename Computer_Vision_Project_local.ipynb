{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac61d1cd-199f-4dd3-886c-1fd8e5b6b378",
   "metadata": {},
   "source": [
    "# Computer Vision Project \n",
    "\n",
    "## Code author: Brewton LOPES MORAIS\n",
    "## Date: 04 May 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10abedc7-bb99-4931-be7c-af444a117845",
   "metadata": {},
   "source": [
    "# Folder requirement \n",
    " The figs_folder variable is a variable containing the name of the folder you're going to save the 16x16 images. Therefore, before running the code, create a folder with name 'images', or any name you may prefer. Also, create a folder named \"images224\" (necessary in the 4th cell) for the 224x224 hand figures or any other name you may prefer (attention to update it in the fourth cell in case you want to change the name). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22770d89-b68a-46f3-af9e-d81abc635620",
   "metadata": {},
   "source": [
    "## Cell 1: Import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902978a8-23ec-4a91-890a-21c7d023e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io #module for dealing with several types of I/O\n",
    "import cv2  #Open CV Library\n",
    "import time \n",
    "from datetime import timedelta\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import image as im\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "figs_folder='images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5adc3fc-f002-4aa0-b092-68a27115f185",
   "metadata": {},
   "source": [
    "## Cell 2: it contains all the functions necessary for the algorithm and for the stocking process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3e4763-5395-4c91-9a8a-b3fda761ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for detecting objects of different sizes based on the input image using the Cascade Method\n",
    "def detect(img, cascade):\n",
    "    # The detected objects are returned as a list of rectangles\n",
    "    # as we update the scale factor by a small factor (0.1~0.2), we can see how time improvement is updated\n",
    "    rects = cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30),\n",
    "                                     flags=cv2.CASCADE_SCALE_IMAGE) #flags parameter has the same meaning for an old cascade\n",
    "    \n",
    "    if len(rects) == 0:\n",
    "        return []\n",
    "    rects[:,2:] += rects[:,:2]\n",
    "    return rects.tolist()\n",
    "\n",
    "# Drawn rectangles over the image for recongnition \n",
    "def draw_rects(img, rects, color):\n",
    "    #(x1, y1) are starting coordinates of rectangle; (x2, y2) are ending coordinates\n",
    "    for x1, y1, x2, y2 in rects:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "# Counter for letters inside figs_folder\n",
    "def count_letter(letter):\n",
    "    l = 0\n",
    "    letter\n",
    "    for fig in os.listdir(figs_folder):\n",
    "        if letter in fig:\n",
    "            l+=1\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7af6e-48a4-4c51-aaf4-6ddeb24db275",
   "metadata": {},
   "source": [
    "## Once you run the third (below) cell, you are going to give the program 3 inputs.\n",
    "1. \"Insert the letter (uppercase): \" Here you tell the program which letter you are going to make with your hand. Example: if you want to make it A, type A and hit Enter.\n",
    "2. \"Insert the maximum number of pictures you want to stock: \" Here you tell how many of the chosen letter you want to stock. For example, 10.\n",
    "3. \"Last image counter: \" I strongly recommend you to put it always 0.\n",
    "\n",
    "About the third input: Here, the last image counter corresponds to last image of a given letter you've saved. It is highly recommended that you run program like the following:\n",
    "You save all the A's you want, and only then you change it to another letter, B, for example. Like that, you can always put 0 in the last input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b083e29-1e8f-48ef-aab6-ba8ac10d0a89",
   "metadata": {},
   "source": [
    "## Order of cell running :\n",
    "\n",
    "    After you have runned the two cells above, you must follow the given order: \n",
    "1. Run cell 3 -> It saves all the images you want. \n",
    "2. Run cell 4 -> It creates/updates dataset.txt. \n",
    "\n",
    "    Now, I assumed you are going to do it again but for other letter.\n",
    "3. Run cell 3 again -> The same as previous, but with a new letter. \n",
    "4. Run cell 4 again -> The same as previous, but with a new letter. \n",
    "\n",
    "5. After saving the data set you want, for exemple: 100 letter for A, B and C, you may verify it on you dataset.txt and on the images folders 'images' and 'images224'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154d498-9338-46a8-8609-b596a068665a",
   "metadata": {},
   "source": [
    "## Cell 3: Local version for Face Detection and CamShift algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3c432-0144-44b8-b017-59046b513657",
   "metadata": {},
   "source": [
    "As you save your images, you can monitor how your face and you hand are being detected on the poped ups windows. Make sure your hand is being well detected by the gray window, avoid letting your head to close of your hand.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7a0a97-54e7-49db-823c-ddf2e35a779a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert the letter (uppercase):  A\n",
      "Insert the maximum number of pictres you want to stock:  10\n",
      "Last image counter:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[] <class 'list'>\n",
      "[[260, 141, 406, 287]] <class 'list'>\n",
      "(3, 10, 1)\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "currentLetter = input(\"Insert the letter (uppercase): \")\n",
    "maximg_counter = int(input(\"Insert the maximum number of pictres you want to stock: \"))\n",
    "last_image_counter = int(input(\"Last image counter: \"))\n",
    "\n",
    "img_counter = last_image_counter\n",
    "\n",
    "cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\") # face detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "margin = 20 # margin for the rectangle drawn \n",
    "\n",
    "track_window = []    # Empty list to stock the rectangle coordinates\n",
    "\n",
    "while len(track_window)==0: # Loop stops as soon as a face is detected\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "        \n",
    "    vis = frame.copy()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    \n",
    "    track_window = detect(gray, cascade) # Empty when there's no face in front of cam\n",
    "    print(track_window, type(track_window))\n",
    "    \n",
    "    draw_rects(vis, track_window, (0, 255, 0))\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "        \n",
    "# After  track window detection, select the coordinates of the first face detected \n",
    "x0, y0, x1, y1 = track_window[0]\n",
    "\n",
    "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "hsv_roi = hsv[y0:y1, x0:x1] # hsv acting over region of interest (track_window) \n",
    "mask_roi = mask[y0:y1, x0:x1] # mask acting over region of interest (track_window) \n",
    "\n",
    "\n",
    "hist = cv2.calcHist( [hsv_roi], [0], mask_roi, [16], [0, 180] )\n",
    "cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Stop criteria\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "print(term_crit)\n",
    "\n",
    "im_w = vis.shape[1] # Image width \n",
    "im_h = vis.shape[0] # Image heigth \n",
    "      \n",
    "track_window_hand = (0, 0, im_h, im_w)\n",
    "\n",
    "while True: \n",
    "    # Create new frame for CamShift to detect the hand\n",
    "    ret2, frame2 = cap.read()\n",
    "    if not ret2:\n",
    "        print(\"Failed to grab frame in second while\")\n",
    "        break\n",
    "    \n",
    "    vis2 = frame2.copy()\n",
    "    \n",
    "    hsv2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)\n",
    "    mask2 = cv2.inRange(hsv2, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "    \n",
    "    # Probability calculation based on the histogram computed for the face\n",
    "    prob = cv2.calcBackProject([hsv2], [0], hist, [0, 180], 1)\n",
    "    prob &= mask2\n",
    "\n",
    "    # Cunning to avoid wrong type in track_window \n",
    "    a, b, c, d = track_window[0]\n",
    "    var = a, b, c, d\n",
    "    rect, track_window_cs = cv2.CamShift(prob, var, term_crit)\n",
    "    x, y, w, h = track_window_cs # Here, track_window is a tuple, since it's an output of CamShift\n",
    "        \n",
    "    # At this point, I've got my face being erased\n",
    "    frame_cs = cv2.rectangle(frame2, (x, y), (x+w, y+h), 255, 2)\n",
    "    cv2.imshow('Test Camshift', frame2)\n",
    "    \n",
    "    prob[y:y+h,x:x+w] = 0 # Erase face probability  \n",
    "\n",
    "    save_prob = prob.copy()\n",
    "    \n",
    "    # Add another camshift here to detect hand\n",
    "    \n",
    "    rect_hand, track_window_hand = cv2.CamShift(prob, track_window_hand, term_crit)\n",
    "    xh, yh, wh, hh = track_window_hand\n",
    "    \n",
    "    # The hand image is sucessfully being detected, however the user must\n",
    "    # be well positioned, i.e, positioning their head away from hand and \n",
    "    # they must be in a well lightned place \n",
    "    \n",
    "    img_hand = cv2.rectangle(prob, (xh,yh), (xh+wh, yh+hh), 255, 2)\n",
    "    cv2.imshow('Test hand', img_hand)\n",
    "\n",
    "    # Here I use the frame save_prob to avoid drawning a rectangle on the output image (the same images we're going to store)\n",
    "    selectedHand =  save_prob[yh-margin:yh+hh+margin, xh-margin:xh+wh+margin+(hh-wh)] # with margin and delta_x = (hh-wh) to make it a square\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "        \n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed : the program saves the images (16x16, 224x224)\n",
    "        \n",
    "        img_name1 = f\"{currentLetter}_{img_counter}_16.jpg\" # currentLetter being the letter theat the user passed as input to save\n",
    "        img_name2 = f\"{currentLetter}_{img_counter}_224.jpg\"\n",
    "        \n",
    "        # Resizing of images \n",
    "        square16 = cv2.resize(selectedHand, dsize=(16,16), interpolation=cv2.INTER_CUBIC ) # resize to 16x16\n",
    "        square224 = cv2.resize(selectedHand, dsize=(224,224), interpolation=cv2.INTER_CUBIC ) # resize to 224x224\n",
    "        \n",
    "        # Storing the 16x16 images to figs_folder\n",
    "        cv2.imwrite(os.path.join(figs_folder, img_name1), square16)\n",
    "        \n",
    "        # Storing the 224x224 images to folder named \"images224\"\n",
    "        cv2.imwrite(os.path.join(\"images224\", img_name2), square224)\n",
    "        \n",
    "        # Print to allow the user to monitor how many images they have saved until current instant\n",
    "        print(f\"snapshot {img_counter} saved to: {img_name1}\")\n",
    "        \n",
    "        # As soon as the img_counter reaches the maximum number specified by the user, program stops automatically\n",
    "        \n",
    "        img_counter += 1\n",
    "        if(img_counter == maximg_counter+last_image_counter):\n",
    "            print(f\"{maximg_counter} images were saved of letter {currentLetter}.\")\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab360e6e-52cc-4633-9f50-82b79dfce4af",
   "metadata": {},
   "source": [
    "## Cell 4: Data set creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04583f7b-4655-4e1b-bb8d-c0bbc29f46ef",
   "metadata": {},
   "source": [
    "The cell below creates the dataset.txt according to the images saved on the previous cell. The user must pay attention: if this cell is runned twice after running the previous, it's going to duplicate the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cee09f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading figures from the following path:\n",
      "\n",
      "C:\\Users\\brewt\\computer_vision\\images\n",
      "\\Listing ... 300  figures\n",
      "['Q_0_16.jpg', 'Q_10_16.jpg', 'Q_11_16.jpg', 'Q_12_16.jpg', 'Q_13_16.jpg', 'Q_14_16.jpg', 'Q_15_16.jpg', 'Q_16_16.jpg', 'Q_17_16.jpg', 'Q_18_16.jpg', 'Q_19_16.jpg', 'Q_1_16.jpg', 'Q_20_16.jpg', 'Q_21_16.jpg', 'Q_22_16.jpg', 'Q_23_16.jpg', 'Q_24_16.jpg', 'Q_25_16.jpg', 'Q_26_16.jpg', 'Q_27_16.jpg', 'Q_28_16.jpg', 'Q_29_16.jpg', 'Q_2_16.jpg', 'Q_30_16.jpg', 'Q_31_16.jpg', 'Q_32_16.jpg', 'Q_33_16.jpg', 'Q_34_16.jpg', 'Q_35_16.jpg', 'Q_36_16.jpg', 'Q_37_16.jpg', 'Q_38_16.jpg', 'Q_39_16.jpg', 'Q_3_16.jpg', 'Q_40_16.jpg', 'Q_41_16.jpg', 'Q_42_16.jpg', 'Q_43_16.jpg', 'Q_44_16.jpg', 'Q_45_16.jpg', 'Q_46_16.jpg', 'Q_47_16.jpg', 'Q_48_16.jpg', 'Q_49_16.jpg', 'Q_4_16.jpg', 'Q_50_16.jpg', 'Q_51_16.jpg', 'Q_52_16.jpg', 'Q_53_16.jpg', 'Q_54_16.jpg', 'Q_55_16.jpg', 'Q_56_16.jpg', 'Q_57_16.jpg', 'Q_58_16.jpg', 'Q_59_16.jpg', 'Q_5_16.jpg', 'Q_60_16.jpg', 'Q_61_16.jpg', 'Q_62_16.jpg', 'Q_63_16.jpg', 'Q_64_16.jpg', 'Q_65_16.jpg', 'Q_66_16.jpg', 'Q_67_16.jpg', 'Q_68_16.jpg', 'Q_69_16.jpg', 'Q_6_16.jpg', 'Q_70_16.jpg', 'Q_71_16.jpg', 'Q_72_16.jpg', 'Q_73_16.jpg', 'Q_74_16.jpg', 'Q_75_16.jpg', 'Q_76_16.jpg', 'Q_77_16.jpg', 'Q_78_16.jpg', 'Q_79_16.jpg', 'Q_7_16.jpg', 'Q_80_16.jpg', 'Q_81_16.jpg', 'Q_82_16.jpg', 'Q_83_16.jpg', 'Q_84_16.jpg', 'Q_85_16.jpg', 'Q_86_16.jpg', 'Q_87_16.jpg', 'Q_88_16.jpg', 'Q_89_16.jpg', 'Q_8_16.jpg', 'Q_90_16.jpg', 'Q_91_16.jpg', 'Q_92_16.jpg', 'Q_93_16.jpg', 'Q_94_16.jpg', 'Q_95_16.jpg', 'Q_96_16.jpg', 'Q_97_16.jpg', 'Q_98_16.jpg', 'Q_99_16.jpg', 'Q_9_16.jpg', 'T_0_16.jpg', 'T_10_16.jpg', 'T_11_16.jpg', 'T_12_16.jpg', 'T_13_16.jpg', 'T_14_16.jpg', 'T_15_16.jpg', 'T_16_16.jpg', 'T_17_16.jpg', 'T_18_16.jpg', 'T_19_16.jpg', 'T_1_16.jpg', 'T_20_16.jpg', 'T_21_16.jpg', 'T_22_16.jpg', 'T_23_16.jpg', 'T_24_16.jpg', 'T_25_16.jpg', 'T_26_16.jpg', 'T_27_16.jpg', 'T_28_16.jpg', 'T_29_16.jpg', 'T_2_16.jpg', 'T_30_16.jpg', 'T_31_16.jpg', 'T_32_16.jpg', 'T_33_16.jpg', 'T_34_16.jpg', 'T_35_16.jpg', 'T_36_16.jpg', 'T_37_16.jpg', 'T_38_16.jpg', 'T_39_16.jpg', 'T_3_16.jpg', 'T_40_16.jpg', 'T_41_16.jpg', 'T_42_16.jpg', 'T_43_16.jpg', 'T_44_16.jpg', 'T_45_16.jpg', 'T_46_16.jpg', 'T_47_16.jpg', 'T_48_16.jpg', 'T_49_16.jpg', 'T_4_16.jpg', 'T_50_16.jpg', 'T_51_16.jpg', 'T_52_16.jpg', 'T_53_16.jpg', 'T_54_16.jpg', 'T_55_16.jpg', 'T_56_16.jpg', 'T_57_16.jpg', 'T_58_16.jpg', 'T_59_16.jpg', 'T_5_16.jpg', 'T_60_16.jpg', 'T_61_16.jpg', 'T_62_16.jpg', 'T_63_16.jpg', 'T_64_16.jpg', 'T_65_16.jpg', 'T_66_16.jpg', 'T_67_16.jpg', 'T_68_16.jpg', 'T_69_16.jpg', 'T_6_16.jpg', 'T_70_16.jpg', 'T_71_16.jpg', 'T_72_16.jpg', 'T_73_16.jpg', 'T_74_16.jpg', 'T_75_16.jpg', 'T_76_16.jpg', 'T_77_16.jpg', 'T_78_16.jpg', 'T_79_16.jpg', 'T_7_16.jpg', 'T_80_16.jpg', 'T_81_16.jpg', 'T_82_16.jpg', 'T_83_16.jpg', 'T_84_16.jpg', 'T_85_16.jpg', 'T_86_16.jpg', 'T_87_16.jpg', 'T_88_16.jpg', 'T_89_16.jpg', 'T_8_16.jpg', 'T_90_16.jpg', 'T_91_16.jpg', 'T_92_16.jpg', 'T_93_16.jpg', 'T_94_16.jpg', 'T_95_16.jpg', 'T_96_16.jpg', 'T_97_16.jpg', 'T_98_16.jpg', 'T_99_16.jpg', 'T_9_16.jpg', 'X_0_16.jpg', 'X_10_16.jpg', 'X_11_16.jpg', 'X_12_16.jpg', 'X_13_16.jpg', 'X_14_16.jpg', 'X_15_16.jpg', 'X_16_16.jpg', 'X_17_16.jpg', 'X_18_16.jpg', 'X_19_16.jpg', 'X_1_16.jpg', 'X_20_16.jpg', 'X_21_16.jpg', 'X_22_16.jpg', 'X_23_16.jpg', 'X_24_16.jpg', 'X_25_16.jpg', 'X_26_16.jpg', 'X_27_16.jpg', 'X_28_16.jpg', 'X_29_16.jpg', 'X_2_16.jpg', 'X_30_16.jpg', 'X_31_16.jpg', 'X_32_16.jpg', 'X_33_16.jpg', 'X_34_16.jpg', 'X_35_16.jpg', 'X_36_16.jpg', 'X_37_16.jpg', 'X_38_16.jpg', 'X_39_16.jpg', 'X_3_16.jpg', 'X_40_16.jpg', 'X_41_16.jpg', 'X_42_16.jpg', 'X_43_16.jpg', 'X_44_16.jpg', 'X_45_16.jpg', 'X_46_16.jpg', 'X_47_16.jpg', 'X_48_16.jpg', 'X_49_16.jpg', 'X_4_16.jpg', 'X_50_16.jpg', 'X_51_16.jpg', 'X_52_16.jpg', 'X_53_16.jpg', 'X_54_16.jpg', 'X_55_16.jpg', 'X_56_16.jpg', 'X_57_16.jpg', 'X_58_16.jpg', 'X_59_16.jpg', 'X_5_16.jpg', 'X_60_16.jpg', 'X_61_16.jpg', 'X_62_16.jpg', 'X_63_16.jpg', 'X_64_16.jpg', 'X_65_16.jpg', 'X_66_16.jpg', 'X_67_16.jpg', 'X_68_16.jpg', 'X_69_16.jpg', 'X_6_16.jpg', 'X_70_16.jpg', 'X_71_16.jpg', 'X_72_16.jpg', 'X_73_16.jpg', 'X_74_16.jpg', 'X_75_16.jpg', 'X_76_16.jpg', 'X_77_16.jpg', 'X_78_16.jpg', 'X_79_16.jpg', 'X_7_16.jpg', 'X_80_16.jpg', 'X_81_16.jpg', 'X_82_16.jpg', 'X_83_16.jpg', 'X_84_16.jpg', 'X_85_16.jpg', 'X_86_16.jpg', 'X_87_16.jpg', 'X_88_16.jpg', 'X_89_16.jpg', 'X_8_16.jpg', 'X_90_16.jpg', 'X_91_16.jpg', 'X_92_16.jpg', 'X_93_16.jpg', 'X_94_16.jpg', 'X_95_16.jpg', 'X_96_16.jpg', 'X_97_16.jpg', 'X_98_16.jpg', 'X_99_16.jpg', 'X_9_16.jpg']\n",
      "\\Reading and storing letters, vector in dataset\n",
      "After stocking (100, 256) (0,)\n",
      "\n",
      "Saving data to text file: dataset_16.txt and dataset_224.txt\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Folder name that is in the same folder as the notebook\n",
    "print('Loading figures from the following path:\\n')\n",
    "print(os.path.abspath(figs_folder))\n",
    "print('\\Listing ...', len(os.listdir(figs_folder)),' figures')\n",
    "print(os.listdir(figs_folder))\n",
    "\n",
    "print('\\Reading and storing letters, vector in dataset')\n",
    "\n",
    "# Create empty lists to store the figures and its labels \n",
    "figs16 = []\n",
    "labels16= []\n",
    "figs224 = []\n",
    "labels224 = []\n",
    "\n",
    "for i in range(last_image_counter, count_letter(currentLetter)):\n",
    "\n",
    "    fig = f\"{currentLetter}_{i}_16.jpg\"\n",
    "    sample16 = im.imread(os.path.join(figs_folder,fig)).ravel()\n",
    "    figs16.insert(len(figs16), sample16)\n",
    "    labels16.append(fig[0])\n",
    "\n",
    "## In case the user also wants to create a data set for the 224x224 images, uncomment the following lines (23 to 26)\n",
    "\n",
    "#     elif '224' in fig:\n",
    "#         sample224 = im.imread(os.path.join(figs_folder,fig)).ravel()\n",
    "#         figs224.insert(len(figs16), sample224)\n",
    "#         labels224.append(fig[0])\n",
    "\n",
    "figs16 = np.array(figs16)\n",
    "figs224 = np.array(figs224)\n",
    "print('After stocking', figs16.shape, figs224.shape) \n",
    "\n",
    "\n",
    "print('\\nSaving data to text file: dataset.txt')\n",
    "# if file does not exist write header \n",
    "if not os.path.isfile('dataset.txt'):\n",
    "    pd.DataFrame(figs16, index=labels16).to_csv('dataset.txt', header=False)\n",
    "else: # else it exists so append without writing the header\n",
    "    pd.DataFrame(figs16, index=labels16).to_csv('dataset.txt', mode = 'a', header=False)\n",
    "    \n",
    "#pd.DataFrame(figs16, index=labels16).to_csv('dataset.txt', header=False)\n",
    "#pd.DataFrame(figs224, index=labels224).to_csv('dataset_224.txt', header=False)\n",
    "print('\\nDone.')\n",
    "\n",
    "lines = open('dataset.txt').readlines()\n",
    "random.shuffle(lines)\n",
    "open('dataset.txt', 'w').writelines(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604307e8-0e7b-46d1-8b8b-ad4fda2c8b4e",
   "metadata": {},
   "source": [
    "## Cell 5: In case you want to check how your figure looks like as a matrix, and as a gray image with 16x16 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21d4d41-2b19-4b87-b9e8-5303895f2cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXEMPLE\n",
      "Reading letter R as a matrix.\n",
      "[[  0   3   2 148 157   1   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 203 158   2   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   3   0 160   0   5   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 243 158 156   0   2   0   0   0   0   0   0   0   0]\n",
      " [  1   2 255 156 255 253   6   1   0   0   0   0   0   0   0   0]\n",
      " [  2   0 254 156 157 255 255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   1 154 253 157 255 242   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0 254 255 159 250 255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 255 252 152 255 253   1   0   0   0   0   0   0   0   0]\n",
      " [  1   0 255 255 254 254 255   0   0   0   0   0   0   0   0   0]\n",
      " [  1   3   0 255 255 255  26   0   0   0   0   0   0   0   0   0]\n",
      " [  0   2   0 255 205 253  25   3   0   0   0   0   0   0   0   0]\n",
      " [  0   2   1 252 255 255 253   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   0 247 137 254   0   2   0   0   0   0   0   0   0   0]\n",
      " [  0   1   0  89   3   0   3   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   3   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('EXEMPLE')\n",
    "file_row = 2 # Change the value in case you want to read another line\n",
    "\n",
    "letter = pd.read_csv('dataset.txt', header=None).iloc[file_row,0]\n",
    "letter_vector= np.array([int(x) for x in pd.read_csv('dataset.txt', header=None).iloc[file_row,1:].values])\n",
    "print('Reading letter', letter, 'as a matrix.')\n",
    "letter_matrix = letter_vector.reshape(16,16)\n",
    "print(letter_matrix)\n",
    "plt.figure()\n",
    "plt.imshow(letter_matrix, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928349d-843f-4c54-9511-5982f6682130",
   "metadata": {},
   "source": [
    "# Note: if after all this you're having problems to understand how the code runs, I can send you a short video (less than 4 minutes) that I have already created to show you how it works.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
